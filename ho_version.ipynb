{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義數據路徑和文件名稱\n",
    "train_folder = \"DS_Dataset\"\n",
    "output_file = \"upload.csv\"\n",
    "zip_file = \"upload.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location 1: Validation MAE: 6.508054005238318\n"
     ]
    }
   ],
   "source": [
    "location = 1\n",
    "\n",
    "train_file = os.path.join(train_folder, f\"L{location}_train.csv\")\n",
    "train_df = pd.read_csv(train_file)\n",
    "\n",
    "# Convert the 'DateTime' column to datetime format\n",
    "train_df['DateTime'] = pd.to_datetime(train_df['DateTime'])\n",
    "\n",
    "# Extract the date part and calculate the day of the year\n",
    "train_df['DayOfYear'] = train_df['DateTime'].dt.dayofyear\n",
    "# Calculate the number of minutes since the start of the day\n",
    "train_df['MinutesSinceStartOfDay'] = train_df['DateTime'].dt.hour * 60 + train_df['DateTime'].dt.minute\n",
    "# Display the updated DataFrame\n",
    "train_df = train_df.drop(columns=['DateTime'])\n",
    "\n",
    "\n",
    "# 創建歷史特徵（上一小時、上一分鐘的數據）\n",
    "# train_df[\"Prev_Hour_Power\"] = train_df[\"Power(mW)\"].shift(1)\n",
    "# train_df[\"Prev_Minute_Power\"] = train_df[\"Power(mW)\"].shift(1)\n",
    "\n",
    "# 特徵與標籤\n",
    "features = [\"WindSpeed(m/s)\", \"Pressure(hpa)\", \"Temperature(°C)\", \"Humidity(%)\", \"Sunlight(Lux)\", \n",
    "            \"DayOfYear\",\"MinutesSinceStartOfDay\"]\n",
    "X = train_df[features].fillna(0)  # 用 0 填充缺失值\n",
    "y = train_df[\"Power(mW)\"]\n",
    "\n",
    "# 切分數據集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 訓練模型\n",
    "model = XGBRegressor(n_estimators=300, learning_rate=0.03, max_depth=10, subsample=0.8, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 驗證模型\n",
    "val_predictions = model.predict(X_val)\n",
    "print(f\"Location {location}: Validation MAE: {np.mean(np.abs(val_predictions - y_val))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 1\n",
    "\n",
    "train_file = os.path.join(train_folder, f\"L{location}_train.csv\")\n",
    "train_df = pd.read_csv(train_file)\n",
    "\n",
    "# Convert the 'DateTime' column to datetime format\n",
    "train_df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "\n",
    "# Extract the date part and calculate the day of the year\n",
    "train_df['DayOfYear'] = train_df['DateTime'].dt.dayofyear\n",
    "# Calculate the number of minutes since the start of the day\n",
    "train_df['MinutesSinceStartOfDay'] = train_df['DateTime'].dt.hour * 60 + train_df['DateTime'].dt.minute\n",
    "# Display the updated DataFrame\n",
    "train_df = train_df.drop(columns=['DateTime'])\n",
    "\n",
    "# 創建歷史特徵（上一小時、上一分鐘的數據）\n",
    "train_df[\"Prev_Hour_Power\"] = train_df[\"Power(mW)\"].shift(1)\n",
    "train_df[\"Prev_Minute_Power\"] = train_df[\"Power(mW)\"].shift(1)\n",
    "\n",
    "# 特徵與標籤\n",
    "features = [\"WindSpeed(m/s)\", \"Pressure(hpa)\", \"Temperature(°C)\", \"Humidity(%)\", \"Sunlight(Lux)\", \n",
    "            \"Hour\", \"Minute\", \"DayOfWeek\", \"Prev_Hour_Power\", \"Prev_Minute_Power\"]\n",
    "X = train_df[features].fillna(0)  # 用 0 填充缺失值\n",
    "y = train_df[\"Power(mW)\"]\n",
    "\n",
    "# 切分數據集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 訓練模型\n",
    "model = XGBRegressor(n_estimators=300, learning_rate=0.03, max_depth=10, subsample=0.8, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 驗證模型\n",
    "val_predictions = model.predict(X_val)\n",
    "print(f\"Location {location}: Validation MAE: {np.mean(np.abs(val_predictions - y_val))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location 1: Validation MAE: 6.508054005238318\n",
      "Location 2: Validation MAE: 7.532916816752552\n",
      "Location 3: Validation MAE: 10.78881835797161\n",
      "Location 4: Validation MAE: 14.005060387564711\n",
      "Location 5: Validation MAE: 12.269447345882865\n",
      "Location 6: Validation MAE: 10.878805857753166\n",
      "Location 7: Validation MAE: 9.77509157279175\n",
      "Location 8: Validation MAE: 7.3333386157581835\n",
      "Location 9: Validation MAE: 6.294463191535495\n",
      "Location 10: Validation MAE: 9.09349078293047\n",
      "Location 11: Validation MAE: 4.763705819122911\n",
      "Location 12: Validation MAE: 5.709341706359989\n",
      "Location 13: Validation MAE: 6.940964623749893\n",
      "Location 14: Validation MAE: 8.237470997026083\n",
      "Location 15: Validation MAE: 7.44105787322778\n",
      "Location 16: Validation MAE: 8.918181295478767\n",
      "Location 17: Validation MAE: 11.874126793936679\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 初始化字典來存儲每個裝置的模型和訓練數據\n",
    "models = {}\n",
    "train_data = {}\n",
    "\n",
    "# 讀取所有訓練文件並為每個裝置訓練模型\n",
    "for location in range(1, 18):\n",
    "    train_file = os.path.join(train_folder, f\"L{location}_train.csv\")\n",
    "    train_df = pd.read_csv(train_file)\n",
    "\n",
    "    train_file = os.path.join(train_folder, f\"L{location}_train.csv\")\n",
    "    train_df = pd.read_csv(train_file)\n",
    "\n",
    "    # Convert the 'DateTime' column to datetime format\n",
    "    train_df['DateTime'] = pd.to_datetime(train_df['DateTime'])\n",
    "\n",
    "    # Extract the date part and calculate the day of the year\n",
    "    train_df['DayOfYear'] = train_df['DateTime'].dt.dayofyear\n",
    "    # Calculate the number of minutes since the start of the day\n",
    "    train_df['MinutesSinceStartOfDay'] = train_df['DateTime'].dt.hour * 60 + train_df['DateTime'].dt.minute\n",
    "    # Display the updated DataFrame\n",
    "    train_df = train_df.drop(columns=['DateTime'])\n",
    "\n",
    "\n",
    "    # 創建歷史特徵（上一小時、上一分鐘的數據）\n",
    "    # train_df[\"Prev_Hour_Power\"] = train_df[\"Power(mW)\"].shift(1)\n",
    "    # train_df[\"Prev_Minute_Power\"] = train_df[\"Power(mW)\"].shift(1)\n",
    "\n",
    "    # 特徵與標籤\n",
    "    features = [\"WindSpeed(m/s)\", \"Pressure(hpa)\", \"Temperature(°C)\", \"Humidity(%)\", \"Sunlight(Lux)\", \n",
    "                \"DayOfYear\",\"MinutesSinceStartOfDay\"]\n",
    "    X = train_df[features].fillna(0)  # 用 0 填充缺失值\n",
    "    y = train_df[\"Power(mW)\"]\n",
    "\n",
    "    # 切分數據集\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 訓練模型\n",
    "    model = XGBRegressor(n_estimators=300, learning_rate=0.03, max_depth=10, subsample=0.8, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 驗證模型\n",
    "    val_predictions = model.predict(X_val)\n",
    "    print(f\"Location {location}: Validation MAE: {np.mean(np.abs(val_predictions - y_val))}\")\n",
    "    # 保存模型和訓練數據\n",
    "    models[location] = model\n",
    "    train_data[location] = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['DayOfYear', 'MinutesSinceStartOfDay'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m closest_row \u001b[38;5;241m=\u001b[39m location_data\u001b[38;5;241m.\u001b[39miloc[(location_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39margsort()[:\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 確保選擇了所有需要的特徵\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m X_pred \u001b[38;5;241m=\u001b[39m \u001b[43mclosest_row\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# 用 0 填充缺失值\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 預測\u001b[39;00m\n\u001b[0;32m     41\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([X_pred\u001b[38;5;241m.\u001b[39mvalues])[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# 確保 X_pred 轉為二維數組\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\meowm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\meowm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\meowm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['DayOfYear', 'MinutesSinceStartOfDay'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "# 讀取 upload.csv\n",
    "upload_path = os.path.join(train_folder, \"upload.csv\")\n",
    "upload_df = pd.read_csv(upload_path, header=0, names=[\"序號\", \"答案\"])\n",
    "\n",
    "# 確保序號列為字符串\n",
    "upload_df[\"序號\"] = upload_df[\"序號\"].astype(str)\n",
    "\n",
    "# 提取時間和裝置代碼特徵\n",
    "upload_df[\"DateTime\"] = pd.to_datetime(upload_df[\"序號\"].str[:12], format=\"%Y%m%d%H%M\")\n",
    "upload_df[\"LocationCode\"] = upload_df[\"序號\"].str[-2:].astype(int)\n",
    "upload_df[\"Hour\"] = upload_df[\"DateTime\"].dt.hour\n",
    "upload_df[\"Minute\"] = upload_df[\"DateTime\"].dt.minute\n",
    "upload_df[\"DayOfWeek\"] = upload_df[\"DateTime\"].dt.dayofweek\n",
    "\n",
    "# 預測每一行的答案\n",
    "predictions = []\n",
    "for _, row in upload_df.iterrows():\n",
    "    location = row[\"LocationCode\"]\n",
    "    model = models[location]  # 使用對應的裝置模型\n",
    "\n",
    "    # 查找對應裝置的特徵數據\n",
    "    location_data = pd.read_csv(os.path.join(train_folder, f\"L{location}_train.csv\"))\n",
    "    location_data[\"DateTime\"] = pd.to_datetime(location_data[\"DateTime\"])\n",
    "\n",
    "    # 計算時間特徵：這一步保證了 'Hour', 'Minute', 'DayOfWeek' 被計算出來\n",
    "    location_data[\"Hour\"] = location_data[\"DateTime\"].dt.hour\n",
    "    location_data[\"Minute\"] = location_data[\"DateTime\"].dt.minute\n",
    "    location_data[\"DayOfWeek\"] = location_data[\"DateTime\"].dt.dayofweek\n",
    "\n",
    "    # 創建歷史特徵（上一小時、上一分鐘的數據）\n",
    "    location_data[\"Prev_Hour_Power\"] = location_data[\"Power(mW)\"].shift(1)\n",
    "    location_data[\"Prev_Minute_Power\"] = location_data[\"Power(mW)\"].shift(1)\n",
    "\n",
    "    # 找到最近的特徵值\n",
    "    closest_row = location_data.iloc[(location_data[\"DateTime\"] - row[\"DateTime\"]).abs().argsort()[:1]]\n",
    "\n",
    "    # 確保選擇了所有需要的特徵\n",
    "    X_pred = closest_row[features].iloc[0].fillna(0)  # 用 0 填充缺失值\n",
    "\n",
    "    # 預測\n",
    "    prediction = model.predict([X_pred.values])[0]  # 確保 X_pred 轉為二維數組\n",
    "    predictions.append(f\"{max(0, round(prediction, 2)):.2f}\")  # 格式化為兩位小數的字符串\n",
    "\n",
    "# 保存預測結果\n",
    "upload_df[\"答案\"] = predictions\n",
    "upload_df[[\"序號\", \"答案\"]].to_csv(output_file, index=False, header=True, encoding='utf-8-sig')\n",
    "\n",
    "# 壓縮為 zip 文件\n",
    "with zipfile.ZipFile(zip_file, 'w') as zf:\n",
    "    zf.write(output_file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
